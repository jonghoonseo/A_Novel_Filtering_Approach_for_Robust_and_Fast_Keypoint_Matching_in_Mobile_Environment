
@inproceedings{chen_robust_2013,
	title = {Robust Feature Matching with Alternate Hough and Inverted Hough Transforms},
	doi = {10.1109/CVPR.2013.356},
	abstract = {We present an algorithm that carries out alternate Hough transform and inverted Hough transform to establish feature correspondences, and enhances the quality of matching in both precision and recall. Inspired by the fact that nearby features on the same object share coherent homographies in matching, we cast the task of feature matching as a density estimation problem in the Hough space spanned by the hypotheses of homographies. Specifically, we project all the correspondences into the Hough space, and determine the correctness of the correspondences by their respective densities. In this way, mutual verification of relevant correspondences is activated, and the precision of matching is boosted. On the other hand, we infer the concerted homographies propagated from the locally grouped features, and enrich the correspondence candidates for each feature. The recall is hence increased. The two processes are tightly coupled. Through iterative optimization, plausible enrichments are gradually revealed while more correct correspondences are detected. Promising experimental results on three benchmark datasets manifest the effectiveness of the proposed approach.},
	booktitle = {2013 {IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	author = {Chen, Hsin-Yi and Lin, Yen-Yu and Chen, Bing-Yu},
	year = {2013},
	keywords = {alternate Hough transform, coherent homography, concerted homography, correspondence enrichment, density estimation problem, Detectors, Estimation, estimation theory, feature extraction, Hough space, Hough transform, Hough transforms, image matching, inverted Hough transform, {IP} networks, iterative methods, iterative optimization, Lighting, optimisation, plausible enrichments, point matching, robust feature matching, Robustness, Transforms},
	pages = {2762--2769},
	file = {Chen et al. - 2013 - Robust Feature Matching with Alternate Hough and I.pdf:E\:\\Papers\\Zotero Repository\\storage\\VXUF65C3\\Chen et al. - 2013 - Robust Feature Matching with Alternate Hough and I.pdf:application/pdf;IEEE Xplore Abstract Record:E\:\\Papers\\Zotero Repository\\storage\\HZUUHWNJ\\abs_all.html:text/html}
}

@inproceedings{csurka_visual_2004,
	title = {Visual categorization with bags of keypoints},
	abstract = {Abstract. We present a novel method for generic visual categorization: the problem of identifying the object content of natural images while generalizing across variations inherent to the object class. This bag of keypoints method is based on vector quantization of affine invariant descriptors of image patches. We propose and compare two alternative implementations using different classifiers: Naïve Bayes and {SVM}. The main advantages of the method are that it is simple, computationally efficient and intrinsically invariant. We present results for simultaneously classifying seven semantic visual categories. These results clearly demonstrate that the method is robust to background clutter and produces good categorization accuracy even without exploiting geometric information. 1.},
	booktitle = {In Workshop on Statistical Learning in Computer Vision, {ECCV}},
	author = {Csurka, Gabriella and Dance, Christopher R. and Fan, Lixin and Willamowski, Jutta and Bray, Cédric},
	year = {2004},
	pages = {1--22},
	file = {Citeseer - Full Text PDF:E\:\\Papers\\Zotero Repository\\storage\\G83RIEUP\\Csurka et al. - 2004 - Visual categorization with bags of keypoints.pdf:application/pdf;Citeseer - Snapshot:E\:\\Papers\\Zotero Repository\\storage\\NMUP59PW\\summary.html:text/html}
}

@inproceedings{barandiaran_comparative_2008,
	title = {Comparative Evaluation of Random Forest and Fern  Classifiers for Real-Time Feature Matching},
	isbn = {978-80-86943-15-2},
	abstract = {Feature or keypoint matching is a critical task in many computer vision applications, such as optical 3D 
reconstruction or optical markerless tracking. These applications demand very accurate and fast matching 
techniques. We present an evaluation and comparison of two keypoint matching strategies based on supervised 
classification for markerless tracking of planar surfaces. We have applied these approaches on an augmented 
reality prototype for indoor and outdoor design review.},
	booktitle = {Proceedings of {WSCG}},
	author = {Barandiaran, Iñigo and Cottez, Charlote and Paloc, Céline and Graña, Manuel},
	year = {2008},
	pages = {59--166},
	file = {F71-full.pdf:E\:\\Papers\\Zotero Repository\\storage\\M9EFAV2C\\F71-full.pdf:application/pdf}
}

@incollection{lepetit_keypoint_2013,
	series = {Advances in Computer Vision and Pattern Recognition},
	title = {Keypoint Recognition Using Random Forests and Random Ferns},
	copyright = {©2013 Springer-Verlag London},
	isbn = {978-1-4471-4928-6, 978-1-4471-4929-3},
	url = {http://link.springer.com/chapter/10.1007/978-1-4471-4929-3_9},
	abstract = {In many 3D object detection and pose estimation problems, run-time performance is of critical importance. However, there usually is time to train the system. We introduce an approach that takes advantage of this fact by formulating the wide-baseline matching of keypoints extracted from the input images to those found in the model images as a classification problem. This shifts much of the computational burden to a training phase and eliminates the need for expensive patch preprocessing, without sacrificing recognition performance. This makes our approach highly suitable for real-time operations on low-powered devices. To this end, we developed two related methods. The first uses random forests that rely on simple binary tests on image intensities surrounding the keypoints. In the second, we flatten the trees to turn them into simple bit strings, which we will refer to as ferns, and combine their output in a Naïve Bayesian manner. Surprisingly, the ferns, while simpler, actually perform better than the trees. This is because the Naïve Bayesian approach benefits more from the thousands of synthetic training examples we can generate than output averaging as usually performed by decision forests. Furthermore, the more general partition that the trees allow does not appear to be of great use for our problem. Parts of this chapter are reprinted, with permission, from Lepetit, Lagger, and Fua, Proc. {IEEE} Conf. Computer Vision and Pattern Recognition ({CVPR}) (2005), © 2005 {IEEE}.},
	language = {en},
	urldate = {2014-02-03},
	booktitle = {Decision Forests for Computer Vision and Medical Image Analysis},
	publisher = {Springer London},
	author = {Lepetit, V. and Fua, P.},
	editor = {Criminisi, A. and Shotton, J.},
	month = jan,
	year = {2013},
	keywords = {Artificial Intelligence (incl. Robotics), Pattern Recognition},
	pages = {111--124},
	file = {Full Text PDF:E\:\\Papers\\Zotero Repository\\storage\\BU8CWFEC\\Lepetit 그리고 Fua - 2013 - Keypoint Recognition Using Random Forests and Rand.pdf:application/pdf;Snapshot:E\:\\Papers\\Zotero Repository\\storage\\HFTZKGX3\\978-1-4471-4929-3_9.html:text/html}
}

@article{ozuysal_fast_2010,
	title = {Fast Keypoint Recognition Using Random Ferns},
	volume = {32},
	issn = {0162-8828},
	doi = {10.1109/TPAMI.2009.23},
	abstract = {While feature point recognition is a key component of modern approaches to object detection, existing approaches require computationally expensive patch preprocessing to handle perspective distortion. In this paper, we show that formulating the problem in a naive Bayesian classification framework makes such preprocessing unnecessary and produces an algorithm that is simple, efficient, and robust. Furthermore, it scales well as the number of classes grows. To recognize the patches surrounding keypoints, our classifier uses hundreds of simple binary features and models class posterior probabilities. We make the problem computationally tractable by assuming independence between arbitrary sets of features. Even though this is not strictly true, we demonstrate that our classifier nevertheless performs remarkably well on image data sets containing very significant perspective changes.},
	number = {3},
	journal = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	author = {Ozuysal, M. and Calonder, M. and Lepetit, V. and Fua, P.},
	month = mar,
	year = {2010},
	keywords = {Bayes methods, classifier, Computer vision, fast keypoint recognition, feature matching, feature point recognition, image classification, image data sets, Image Processing and Computer Vision, image registration, naive Bayesian., naive Bayesian classification framework, object detection, object recognition, posterior probabilities, probability, random ferns, tracking},
	pages = {448--461},
	file = {IEEE Xplore Abstract Record:E\:\\Papers\\Zotero Repository\\storage\\KSSAPIZ9\\abs_all.html:text/html;IEEE Xplore Full Text PDF:E\:\\Papers\\Zotero Repository\\storage\\SDRBCQMR\\Ozuysal et al. - 2010 - Fast Keypoint Recognition Using Random Ferns.pdf:application/pdf}
}

@inproceedings{muja_fast_2012,
	title = {Fast Matching of Binary Features},
	doi = {10.1109/CRV.2012.60},
	abstract = {There has been growing interest in the use of binary-valued features, such as {BRIEF}, {ORB}, and {BRISK} for efficient local feature matching. These binary features have several advantages over vector-based features as they can be faster to compute, more compact to store, and more efficient to compare. Although it is fast to compute the Hamming distance between pairs of binary features, particularly on modern architectures, it can still be too slow to use linear search in the case of large datasets. For vector-based features, such as {SIFT} and {SURF}, the solution has been to use approximate nearest-neighbor search, but these existing algorithms are not suitable for binary features. In this paper we introduce a new algorithm for approximate matching of binary features, based on priority search of multiple hierarchical clustering trees. We compare this to existing alternatives, and show that it performs well for large datasets, both in terms of speed and memory efficiency.},
	booktitle = {2012 Ninth Conference on Computer and Robot Vision ({CRV})},
	author = {Muja, M. and Lowe, D.G.},
	month = may,
	year = {2012},
	keywords = {approximate matching, Approximation algorithms, binary features, binary-valued features, {BRIEF}, {BRISK}, Buildings, Clustering algorithms, fast matching, feature extraction, feature matching, Hamming distance, hierarchical clustering trees, image matching, large datasets, Libraries, linear search, local feature matching, memory efficiency, nearest neighbors, nearest-neighbor search, Nearest neighbor searches, {ORB}, pattern clustering, search problems, {SIFT}, speed efficiency, {SURF}, trees (mathematics), vector-based features, Vectors},
	pages = {404--410},
	file = {IEEE Xplore Abstract Record:E\:\\Papers\\Zotero Repository\\storage\\MFEX5JJ9\\abs_all.html:text/html;IEEE Xplore Full Text PDF:E\:\\Papers\\Zotero Repository\\storage\\78FQUVH9\\Muja 그리고 Lowe - 2012 - Fast Matching of Binary Features.pdf:application/pdf}
}

@inproceedings{choi_smart_2014,
	title = {Smart Booklet: Tour guide system with mobile augmented reality},
	shorttitle = {Smart Booklet},
	doi = {10.1109/ICCE.2014.6776038},
	abstract = {This paper presents a mobile tour guide system with augmented reality, called Smart Booklet. The system enables tourists to have more informative, interactive and user-specific experiences with augmented information by recognizing/tracking the contents of an off-line tour booklet. For a stand-alone mobile system, demanding low computational cost, an image matching technique based on the combination of two binary feature descriptors are applied. Our proposed system can be applicable to many areas such as education and entertainment industries.},
	booktitle = {2014 {IEEE} International Conference on Consumer Electronics ({ICCE})},
	author = {Choi, Heeseung and Han, Gyu Chull and Kim, Ig-jae},
	month = jan,
	year = {2014},
	keywords = {augmented information, augmented reality, binary feature descriptors, computational cost, Databases, feature extraction, image matching, image matching technique, Image recognition, informative-interactive-user-specific experiences, mobile augmented reality, Mobile communication, mobile computing, mobile tour guide system, offline tour booklet content recognition, offline tour booklet content tracking, Robustness, Smart Booklet, Solid modeling, stand-alone mobile system, target tracking, travel industry},
	pages = {353--354},
	file = {IEEE Xplore Abstract Record:E\:\\Papers\\Zotero Repository\\storage\\WWV3N3MG\\abs_all.html:text/html;IEEE Xplore Full Text PDF:E\:\\Papers\\Zotero Repository\\storage\\CC5BSN6H\\Choi et al. - 2014 - Smart Booklet Tour guide system with mobile augme.pdf:application/pdf}
}

@inproceedings{beis_shape_1997,
	title = {Shape indexing using approximate nearest-neighbour search in high-dimensional spaces},
	doi = {10.1109/CVPR.1997.609451},
	abstract = {Shape indexing is a way of making rapid associations between features detected in an image and object models that could have produced them. When model databases are large, the use of high-dimensional features is critical, due to the improved level of discrimination they can provide. Unfortunately, finding the nearest neighbour to a query point rapidly becomes inefficient as the dimensionality of the feature space increases. Past indexing methods have used hash tables for hypothesis recovery, but only in low-dimensional situations. In this paper we show that a new variant of the k-d tree search algorithm makes indexing in higher-dimensional spaces practical. This Best Bin First, or {BBF} search is an approximate algorithm which finds the nearest neighbour for a large fraction of the queries, and a very close neighbour in the remaining cases. The technique has been integrated into a fully developed recognition system, which is able to detect complex objects in real, cluttered scenes in just a few seconds},
	booktitle = {, 1997 {IEEE} Computer Society Conference on Computer Vision and Pattern Recognition, 1997. Proceedings},
	author = {Beis, J.S. and Lowe, D.G.},
	month = jun,
	year = {1997},
	keywords = {approximate algorithm, approximate nearest-neighbour search, Computer science, Computer vision, feature extraction, features detection, hash tables, high-dimensional spaces, hypothesis recovery, Image databases, image models, indexing, indexing methods, k-d tree search algorithm, Layout, model databases, nearest neighbour, Neural networks, object detection, object models, query point, Shape, shape indexing, Spatial databases, tree data structures, tree searching, visual databases},
	pages = {1000--1006},
	file = {Beis 그리고 Lowe - 1997 - Shape indexing using approximate nearest-neighbour.pdf:E\:\\Papers\\Zotero Repository\\storage\\NHZK3XVC\\Beis 그리고 Lowe - 1997 - Shape indexing using approximate nearest-neighbour.pdf:application/pdf;IEEE Xplore Abstract Record:E\:\\Papers\\Zotero Repository\\storage\\TPWPI2PA\\abs_all.html:text/html}
}

@article{lepetit_keypoint_2006,
	title = {Keypoint recognition using randomized trees},
	volume = {28},
	issn = {0162-8828},
	doi = {10.1109/TPAMI.2006.188},
	abstract = {In many 3D object-detection and pose-estimation problems, runtime performance is of critical importance. However, there usually is time to train the system, which we would show to be very useful. Assuming that several registered images of the target object are available, we developed a keypoint-based approach that is effective in this context by formulating wide-baseline matching of keypoints extracted from the input images to those found in the model images as a classification problem. This shifts much of the computational burden to a training phase, without sacrificing recognition performance. As a result, the resulting algorithm is robust, accurate, and fast-enough for frame-rate performance. This reduction in runtime computational complexity is our first contribution. Our second contribution is to show that, in this context, a simple and fast keypoint detector suffices to support detection and tracking even under large perspective and scale variations. While earlier methods require a detector that can be expected to produce very repeatable results, in general, which usually is very time-consuming, we simply find the most repeatable object keypoints for the specific target object during the training phase. We have incorporated these ideas into a real-time system that detects planar, nonplanar, and deformable objects. It then estimates the pose of the rigid ones and the deformations of the others},
	number = {9},
	journal = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	author = {Lepetit, V. and Fua, P.},
	month = sep,
	year = {2006},
	keywords = {3D object-detection, Classification tree analysis, classifier design and evaluation, computational complexity, Computer vision, Deformable models, edge and feature detection., feature extraction, image classification, Image Processing and Computer Vision, keypoint recognition, object detection, object recognition, Pattern Recognition, Phase detection, Phase estimation, pose-estimation problem, Processor scheduling, randomized trees, Robustness, Runtime, statistical, Statistical learning, tracking, trees (mathematics)},
	pages = {1465--1479},
	file = {IEEE Xplore Abstract Record:E\:\\Papers\\Zotero Repository\\storage\\NRRSTFCW\\abs_all.html:text/html;IEEE Xplore Full Text PDF:E\:\\Papers\\Zotero Repository\\storage\\XH9F9NDX\\Lepetit 그리고 Fua - 2006 - Keypoint recognition using randomized trees.pdf:application/pdf}
}

@inproceedings{gionis_similarity_1999,
	address = {San Francisco, {CA}, {USA}},
	series = {{VLDB} '99},
	title = {Similarity Search in High Dimensions via Hashing},
	isbn = {1-55860-615-7},
	url = {http://dl.acm.org/citation.cfm?id=645925.671516},
	urldate = {2014-07-19},
	booktitle = {Proceedings of the 25th International Conference on Very Large Data Bases},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Gionis, Aristides and Indyk, Piotr and Motwani, Rajeev},
	year = {1999},
	pages = {518--529},
	file = {Gionis et al. - 1999 - Similarity Search in High Dimensions via Hashing.pdf:E\:\\Papers\\Zotero Repository\\storage\\W6I9RE9V\\Gionis et al. - 1999 - Similarity Search in High Dimensions via Hashing.pdf:application/pdf;Hashing.ppt:E\:\\Papers\\Zotero Repository\\storage\\66IF5B8Q\\Hashing.ppt:application/msword}
}

@inproceedings{andoni_near-optimal_2006,
	title = {Near-Optimal Hashing Algorithms for Approximate Nearest Neighbor in High Dimensions},
	doi = {10.1109/FOCS.2006.49},
	abstract = {We present an algorithm for the c-approximate nearest neighbor problem in a d-dimensional Euclidean space, achieving query time of O(dn 1c2/+o(1)) and space O(dn + n1+1c2/+o(1)). This almost matches the lower bound for hashing-based algorithm recently obtained in (R. Motwani et al., 2006). We also obtain a space-efficient version of the algorithm, which uses dn+n {logO}(1) n space, with a query time of {dnO}(1/c2). Finally, we discuss practical variants of the algorithms that utilize fast bounded-distance decoders for the Leech lattice},
	booktitle = {47th Annual {IEEE} Symposium on Foundations of Computer Science, 2006. {FOCS} '06},
	author = {Andoni, A and Indyk, P.},
	month = oct,
	year = {2006},
	keywords = {Approximation algorithms, bounded-distance decoder, c-approximate nearest neighbor, computational complexity, data compression, Data mining, Data structures, d-dimensional Euclidean space, Decoding, file organisation, Image databases, Lattices, Leech lattice, Nearest neighbor searches, near-optimal hashing algorithms, Probes, Spatial databases},
	pages = {459--468},
	file = {IEEE Xplore Abstract Record:E\:\\Papers\\Zotero Repository\\storage\\D6P7V2QS\\abs_all.html:text/html;IEEE Xplore Full Text PDF:E\:\\Papers\\Zotero Repository\\storage\\TJ4UKVTK\\Andoni 그리고 Indyk - 2006 - Near-Optimal Hashing Algorithms for Approximate Ne.pdf:application/pdf}
}

@article{muja_scalable_2014,
	title = {Scalable Nearest Neighbor Algorithms for High Dimensional Data},
	volume = {36},
	issn = {0162-8828},
	doi = {10.1109/TPAMI.2014.2321376},
	abstract = {For many computer vision and machine learning problems, large training sets are key for good performance. However, the most computationally expensive part of many computer vision and machine learning algorithms consists of finding nearest neighbor matches to high dimensional vectors that represent the training data. We propose new algorithms for approximate nearest neighbor matching and evaluate and compare them with previous algorithms. For matching high dimensional features, we find two algorithms to be the most efficient: the randomized k-d forest and a new algorithm proposed in this paper, the priority search k-means tree. We also propose a new algorithm for matching binary features by searching multiple hierarchical clustering trees and show it outperforms methods typically used in the literature. We show that the optimal nearest neighbor algorithm and its parameters depend on the data set characteristics and describe an automated configuration procedure for finding the best algorithm to search a particular data set. In order to scale to very large data sets that would otherwise not fit in the memory of a single machine, we propose a distributed nearest neighbor matching framework that can be used with any of the algorithms described in the paper. All this research has been released as an open source library called fast library for approximate nearest neighbors ({FLANN}), which has been incorporated into {OpenCV} and is now one of the most popular libraries for nearest neighbor matching.},
	number = {11},
	journal = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	author = {Muja, M. and Lowe, D.G.},
	month = nov,
	year = {2014},
	keywords = {algorithm configuration, approximate search, Approximation algorithms, Approximation methods, automated configuration procedure, big data, Clustering algorithms, Computer vision, distributed nearest neighbor matching framework, fast library for approximate nearest neighbors, {FLANN}, high dimensional data, high dimensional feature matching, high dimensional vectors, image matching, learning (artificial intelligence), Machine learning algorithms, machine learning problems, multiple hierarchical clustering trees, Nearest neighbor search, open source library, Partitioning algorithms, priority search k-means tree, randomized k-d forest algorithm, scalable nearest neighbor algorithms, search problems, trees (mathematics), Vegetation},
	pages = {2227--2240},
	file = {IEEE Xplore Abstract Record:E\:\\Papers\\Zotero Repository\\storage\\7SSANUTZ\\abs_all.html:text/html;Muja 그리고 Lowe - 2014 - Scalable Nearest Neighbor Algorithms for High Dime.pdf:E\:\\Papers\\Zotero Repository\\storage\\ECE72WTF\\Muja 그리고 Lowe - 2014 - Scalable Nearest Neighbor Algorithms for High Dime.pdf:application/pdf}
}

@article{pauleve_locality_2010,
	title = {Locality sensitive hashing: A comparison of hash function types and querying mechanisms},
	volume = {31},
	issn = {0167-8655},
	shorttitle = {Locality sensitive hashing},
	url = {http://www.sciencedirect.com/science/article/pii/S0167865510001169},
	doi = {10.1016/j.patrec.2010.04.004},
	abstract = {It is well known that high-dimensional nearest neighbor retrieval is very expensive. Dramatic performance gains are obtained using approximate search schemes, such as the popular Locality-Sensitive Hashing ({LSH}). Several extensions have been proposed to address the limitations of this algorithm, in particular, by choosing more appropriate hash functions to better partition the vector space. All the proposed extensions, however, rely on a structured quantizer for hashing, poorly fitting real data sets, limiting its performance in practice. In this paper, we compare several families of space hashing functions in a real setup, namely when searching for high-dimension {SIFT} descriptors. The comparison of random projections, lattice quantizers, k-means and hierarchical k-means reveal that unstructured quantizer significantly improves the accuracy of {LSH}, as it closely fits the data in the feature space. We then compare two querying mechanisms introduced in the literature with the one originally proposed in {LSH}, and discuss their respective merits and limitations.},
	number = {11},
	urldate = {2014-11-08},
	journal = {Pattern Recognition Letters},
	author = {Paulevé, Loïc and Jégou, Hervé and Amsaleg, Laurent},
	month = aug,
	year = {2010},
	keywords = {Database searching, Image databases, Information retrieval, {LSH}, Quantization, Search methods},
	pages = {1348--1358},
	file = {PJA10.pdf:E\:\\Papers\\Zotero Repository\\storage\\348WNZK7\\PJA10.pdf:application/pdf;ScienceDirect Snapshot:E\:\\Papers\\Zotero Repository\\storage\\SR3GST9Q\\S0167865510001169.html:text/html}
}

@inproceedings{nister_scalable_2006,
	title = {Scalable Recognition with a Vocabulary Tree},
	volume = {2},
	doi = {10.1109/CVPR.2006.264},
	abstract = {A recognition scheme that scales efficiently to a large number of objects is presented. The efficiency and quality is exhibited in a live demonstration that recognizes {CD}-covers from a database of 40000 images of popular music {CD}’s. The scheme builds upon popular techniques of indexing descriptors extracted from local regions, and is robust to background clutter and occlusion. The local region descriptors are hierarchically quantized in a vocabulary tree. The vocabulary tree allows a larger and more discriminatory vocabulary to be used efficiently, which we show experimentally leads to a dramatic improvement in retrieval quality. The most significant property of the scheme is that the tree directly defines the quantization. The quantization and the indexing are therefore fully integrated, essentially being one and the same. The recognition quality is evaluated through retrieval on a database with ground truth, showing the power of the vocabulary tree approach, going as high as 1 million images.},
	booktitle = {2006 {IEEE} Computer Society Conference on Computer Vision and Pattern Recognition},
	author = {Nister, D. and Stewenius, H.},
	year = {2006},
	keywords = {Computer vision, Frequency, Image databases, Image recognition, indexing, Quantization, Robustness, Spatial databases, Visualization, vocabulary},
	pages = {2161--2168},
	file = {IEEE Xplore Abstract Record:E\:\\Papers\\Zotero Repository\\storage\\SU2GW38F\\abs_all.html:text/html;IEEE Xplore Full Text PDF:E\:\\Papers\\Zotero Repository\\storage\\6N6AHFKV\\Nister 그리고 Stewenius - 2006 - Scalable Recognition with a Vocabulary Tree.pdf:application/pdf}
}

@inproceedings{saffari_-line_2009,
	title = {On-line Random Forests},
	doi = {10.1109/ICCVW.2009.5457447},
	abstract = {Random Forests ({RFs}) are frequently used in many computer vision and machine learning applications. Their popularity is mainly driven by their high computational efficiency during both training and evaluation while achieving state-of-the-art results. However, in most applications {RFs} are used off-line. This limits their usability for many practical problems, for instance, when training data arrives sequentially or the underlying distribution is continuously changing. In this paper, we propose a novel on-line random forest algorithm. We combine ideas from on-line bagging, extremely randomized forests and propose an on-line decision tree growing procedure. Additionally, we add a temporal weighting scheme for adaptively discarding some trees based on their out-of-bag-error in given time intervals and consequently growing of new trees. The experiments on common machine learning data sets show that our algorithm converges to the performance of the off-line {RF}. Additionally, we conduct experiments for visual tracking, where we demonstrate real-time state-of-the-art performance on well-known scenarios and show good performance in case of occlusions and appearance changes where we outperform trackers based on on-line boosting. Finally, we demonstrate the usability of on-line {RFs} on the task of interactive real-time segmentation.},
	booktitle = {2009 {IEEE} 12th International Conference on Computer Vision Workshops ({ICCV} Workshops)},
	author = {Saffari, A. and Leistner, C. and Santner, J. and Godec, M. and Bischof, H.},
	month = sep,
	year = {2009},
	keywords = {Application software, Bagging, Computational efficiency, Computer vision, decision trees, image segmentation, interactive real-time segmentation, learning (artificial intelligence), Machine learning, Machine learning algorithms, online decision tree, online random forest algorithm, Radio frequency, Training data, Usability},
	pages = {1393--1400},
	file = {IEEE Xplore Abstract Record:E\:\\Papers\\Zotero Repository\\storage\\IZMZGQUG\\abs_all.html:text/html;IEEE Xplore Full Text PDF:E\:\\Papers\\Zotero Repository\\storage\\B5DRCZ4P\\Saffari et al. - 2009 - On-line Random Forests.pdf:application/pdf}
}

@article{gast_very_2013,
	title = {Very large scale nearest neighbor search: ideas, strategies and challenges},
	volume = {2},
	issn = {2192-6611, 2192-662X},
	shorttitle = {Very large scale nearest neighbor search},
	url = {http://link.springer.com/article/10.1007/s13735-013-0046-4},
	doi = {10.1007/s13735-013-0046-4},
	abstract = {Web-scale databases and big data collections are computationally challenging to analyze and search. Similarity or more precisely nearest neighbor searches are thus crucial in the analysis, indexing and utilization of these massive multimedia databases. In this work, we begin by reviewing the top approaches from the research literature in the past decade. Furthermore, we evaluate the scalability and computational complexity as the feature complexity and database size vary. For the experiments, we used two different data sets with different dimensionalities. The results reveal interesting insights regarding the index structures and their behavior when the data set size is increased. We also summarized the ideas, strategies and challenges for the future.},
	language = {en},
	number = {4},
	urldate = {2014-11-10},
	journal = {International Journal of Multimedia Information Retrieval},
	author = {Gast, Erik and Oerlemans, Ard and Lew, Michael S.},
	month = nov,
	year = {2013},
	keywords = {\$\$k\$\$
                          
                            
                              k
                            
                          
                        -nearest neighbors, big data, Computer Science, general, Data Mining and Knowledge Discovery, High performance indexing, Image Processing and Computer Vision, Information Storage and Retrieval, Information Systems Applications (incl. Internet), Large scale retrieval, Multimedia Information Systems, Similarity search, Web scale search},
	pages = {229--241},
	file = {Full Text PDF:E\:\\Papers\\Zotero Repository\\storage\\5XJI7W8N\\Gast et al. - 2013 - Very large scale nearest neighbor search ideas, s.pdf:application/pdf;Snapshot:E\:\\Papers\\Zotero Repository\\storage\\7KQ3CG76\\s13735-013-0046-4.html:text/html}
}

@article{friedman_algorithm_1977,
	title = {An Algorithm for Finding Best Matches in Logarithmic Expected Time},
	volume = {3},
	issn = {0098-3500},
	url = {http://doi.acm.org/10.1145/355744.355745},
	doi = {10.1145/355744.355745},
	number = {3},
	urldate = {2014-11-15},
	journal = {{ACM} Trans. Math. Softw.},
	author = {Friedman, Jerome H. and Bentley, Jon Louis and Finkel, Raphael Ari},
	month = sep,
	year = {1977},
	pages = {209--226}
}

@inproceedings{muja_fast_2009,
	title = {Fast approximate nearest neighbors with automatic algorithm configuration},
	abstract = {nearest-neighbors search, randomized kd-trees, hierarchical k-means tree, clustering. For many computer vision problems, the most time consuming component consists of nearest neighbor matching in high-dimensional spaces. There are no known exact algorithms for solving these high-dimensional problems that are faster than linear search. Approximate algorithms are known to provide large speedups with only minor loss in accuracy, but many such algorithms have been published with only minimal guidance on selecting an algorithm and its parameters for any given problem. In this paper, we describe a system that answers the question, “What is the fastest approximate nearest-neighbor algorithm for my data? ” Our system will take any given dataset and desired degree of precision and use these to automatically determine the best algorithm and parameter values. We also describe a new algorithm that applies priority search on hierarchical k-means trees, which we have found to provide the best known performance on many datasets. After testing a range of alternatives, we have found that multiple randomized k-d trees provide the best performance for other datasets. We are releasing public domain code that implements these approaches. This library provides about one order of magnitude improvement in query time over the best previously available software and provides fully automated parameter selection. 1},
	booktitle = {In {VISAPP} International Conference on Computer Vision Theory and Applications},
	author = {Muja, Marius and Lowe, David G.},
	year = {2009},
	pages = {331--340},
	file = {Citeseer - Snapshot:E\:\\Papers\\Zotero Repository\\storage\\595HRG6B\\summary.html:text/html;Muja_Lowe_2009_Fast approximate nearest neighbors with automatic algorithm configuration.pdf:E\:\\Papers\\Zotero Repository\\storage\\FHHM4PGV\\Muja_Lowe_2009_Fast approximate nearest neighbors with automatic algorithm configuration.pdf:application/pdf}
}

@article{bentley_multidimensional_1975,
	title = {Multidimensional Binary Search Trees Used for Associative Searching},
	volume = {18},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/361002.361007},
	doi = {10.1145/361002.361007},
	abstract = {This paper develops the multidimensional binary search tree (or k-d tree, where k is the dimensionality of the search space) as a data structure for storage of information to be retrieved by associative searches. The k-d tree is defined and examples are given. It is shown to be quite efficient in its storage requirements. A significant advantage of this structure is that a single data structure can handle many types of queries very efficiently. Various utility algorithms are developed; their proven average running times in an n record file are: insertion, O(log n); deletion of the root, O(n(k-1)/k); deletion of a random node, O(log n); and optimization (guarantees logarithmic performance of searches), O(n log n). Search algorithms are given for partial match queries with t keys specified [proven maximum running time of O(n(k-t)/k)] and for nearest neighbor queries [empirically observed average running time of O(log n).] These performances far surpass the best currently known algorithms for these tasks. An algorithm is presented to handle any general intersection query. The main focus of this paper is theoretical. It is felt, however, that k-d trees could be quite useful in many applications, and examples of potential uses are given.},
	number = {9},
	urldate = {2014-11-15},
	journal = {Commun. {ACM}},
	author = {Bentley, Jon Louis},
	month = sep,
	year = {1975},
	keywords = {associative retrieval, attribute, binary search trees, binary tree insertion, information retrieval system, intersection queries, key, nearest neighbor queries, partial match queries},
	pages = {509--517},
	file = {Bentley - 1975 - Multidimensional Binary Search Trees Used for Asso.pdf:E\:\\Papers\\Zotero Repository\\storage\\NWA2T97F\\Bentley - 1975 - Multidimensional Binary Search Trees Used for Asso.pdf:application/pdf}
}

@article{sproull_refinements_1991,
	title = {Refinements to nearest-neighbor searching in k-dimensional trees},
	volume = {6},
	issn = {0178-4617, 1432-0541},
	url = {http://link.springer.com/article/10.1007/BF01759061},
	doi = {10.1007/BF01759061},
	abstract = {This note presents a simplification and generalization of an algorithm for searchingk-dimensional trees for nearest neighbors reported by Friedmanet al [3]. If the distance between records is measured {usingL} 2 , the Euclidean norm, the data structure used by the algorithm to determine the bounds of the search space can be simplified to a single number. Moreover, because distance measurements {inL} 2 are rotationally invariant, the algorithm can be generalized to allow a partition plane to have an arbitrary orientation, rather than insisting that it be perpendicular to a coordinate axis, as in the original algorithm. When ak-dimensional tree is built, this plane can be found from the principal eigenvector of the covariance matrix of the records to be partitioned. These techniques and others yield variants ofk-dimensional trees customized for specific applications. It is wrong to assume thatk-dimensional trees guarantee that a nearest-neighbor query completes in logarithmic expected time. For smallk, logarithmic behavior is observed on all but tiny trees. However, for largerk, logarithmic behavior is achievable only with extremely large numbers of records. Fork = 16, a search of ak-dimensional tree of 76,000 records examines almost every record.},
	language = {en},
	number = {1-6},
	urldate = {2014-11-15},
	journal = {Algorithmica},
	author = {Sproull, Robert F.},
	month = jun,
	year = {1991},
	keywords = {Algorithm Analysis and Problem Complexity, Algorithms, Computer Systems Organization and Communication Networks, Data Structures, Cryptology and Information Theory, k-dimensional tree, Mathematics of Computing, nearest-neighbor search, Searching, Theory of Computation},
	pages = {579--589},
	file = {Snapshot:E\:\\Papers\\Zotero Repository\\storage\\DGHAWQ4P\\BF01759061.html:text/html}
}

@article{arya_optimal_1998,
	title = {An Optimal Algorithm for Approximate Nearest Neighbor Searching Fixed Dimensions},
	volume = {45},
	issn = {0004-5411},
	url = {http://doi.acm.org/10.1145/293347.293348},
	doi = {10.1145/293347.293348},
	abstract = {Consider a set of S of n data points  in real d-dimensional space, Rd, where distances are measured using any Minkowski metric. In nearest neighbor searching, we preprocess S into a data structure, so that given any query point q ∈ Rd, is the closest point of S to q can be reported quickly. Given any positive real \&egr;, data point p is a (1 +\&egr;)-approximate nearest neighbor of q if its distance from q is within a factor of (1 + \&egr;) of the distance to the true nearest neighbor. We show that it is possible to preprocess a    set of n points in     Rd in O(dn log n) time and O(dn) space, so that given a query point  q  ∈ Rd, and \&egr; {\textgreater} 0, a (1 + \&egr;)-approximate nearest neighbor of q can be computed in O(cd, \&egr; log n) time, where cd,\&egr;≤d  1 + 6d/e;d is a factor depending only on dimension and \&egr;. In general, we show that given an integer k ≥ 1, (1 + \&egr;)-approximations  to the  k nearest neighbors of q can  be computed in additional O(kd log n) time.},
	number = {6},
	urldate = {2014-11-15},
	journal = {J. {ACM}},
	author = {Arya, Sunil and Mount, David M. and Netanyahu, Nathan S. and Silverman, Ruth and Wu, Angela Y.},
	month = nov,
	year = {1998},
	keywords = {Approximation algorithms, box-decomposition trees, closet-point queries, nearest neighbor searching, post-office problem, priority search},
	pages = {891--923}
}

@inproceedings{jia_optimizing_2010,
	title = {Optimizing kd-trees for scalable visual descriptor indexing},
	doi = {10.1109/CVPR.2010.5540006},
	abstract = {In this paper, we attempt to scale up the kd-tree indexing methods for large-scale vision applications, e.g., indexing a large number of {SIFT} features and other types of visual descriptors. To this end, we propose an effective approach to generate near-optimal binary space partitioning and need low time cost to access the nodes in the query stage. First, we relax the coordinate-axis-alignment constraint in partition axis selection used in conventional kd-trees, and form a partition axis with the great variance by combining a few coordinate axes in a binary manner for each node, which yields better space partitioning and requires almost the same time cost to visit internal nodes during the query stage thanks to cheap projection operations. Then, we introduce a simple but very effective scheme to guarantee the partition axis of each internal node is orthogonal to or parallel with those of its ancestors, which leads to efficient distance computation between a query point and the cell associated with each node and yields fast priority search. Compared with the conventional kd-trees, our approach takes a little more tree construction time, but obtains much better nearest neighbor search performance. Experimental results on large scale local patch indexing and image search with tiny images show that our approach outperforms the state-of-the-art kd-tree based indexing methods.},
	booktitle = {2010 {IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	author = {Jia, You and Wang, Jingdong and Zeng, Gang and Zha, Hongbin and Hua, Xian-Sheng},
	month = jun,
	year = {2010},
	keywords = {Application software, Asia, binary space partitioning, Computer vision, Costs, distance computation, Image databases, indexing, kd-tree indexing method, Large-scale systems, local patch indexing, Nearest neighbor searches, Neural networks, {SIFT} feature, Spatial databases, visual descriptor indexing, vocabulary},
	pages = {3392--3399},
	file = {IEEE Xplore Abstract Record:E\:\\Papers\\Zotero Repository\\storage\\QQZ73PWT\\login.html:text/html}
}

@inproceedings{silpa-anan_optimised_2008,
	title = {Optimised {KD}-trees for fast image descriptor matching},
	doi = {10.1109/CVPR.2008.4587638},
	abstract = {In this paper, we look at improving the {KD}-tree for a specific usage: indexing a large number of {SIFT} and other types of image descriptors. We have extended priority search, to priority search among multiple trees. By creating multiple {KD}-trees from the same data set and simultaneously searching among these trees, we have improved the {KD}-treepsilas search performance significantly.We have also exploited the structure in {SIFT} descriptors (or structure in any data set) to reduce the time spent in backtracking. By using Principal Component Analysis to align the principal axes of the data with the coordinate axes, we have further increased the {KD}-treepsilas search performance.},
	booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition, 2008. {CVPR} 2008},
	author = {Silpa-Anan, C. and Hartley, R.},
	month = jun,
	year = {2008},
	keywords = {Application software, binary search trees, Binary trees, Computer vision, Image databases, image descriptor matching, image matching, Image recognition, Image retrieval, indexing, multiple {KD}-trees, principal component analysis, Search methods, {SIFT} descriptors, trees (mathematics)},
	pages = {1--8},
	file = {IEEE Xplore Abstract Record:E\:\\Papers\\Zotero Repository\\storage\\IW3Z9XGD\\login.html:text/html}
}

@inproceedings{dasgupta_random_2008,
	address = {New York, {NY}, {USA}},
	series = {{STOC} '08},
	title = {Random Projection Trees and Low Dimensional Manifolds},
	isbn = {978-1-60558-047-0},
	url = {http://doi.acm.org/10.1145/1374376.1374452},
	doi = {10.1145/1374376.1374452},
	abstract = {We present a simple variant of the k-d tree which automatically adapts to intrinsic low dimensional structure in data without having to explicitly learn this structure.},
	urldate = {2014-11-15},
	booktitle = {Proceedings of the Fortieth Annual {ACM} Symposium on Theory of Computing},
	publisher = {{ACM}},
	author = {Dasgupta, Sanjoy and Freund, Yoav},
	year = {2008},
	keywords = {curse of dimension, k-d tree, manifold, random projection},
	pages = {537--546}
}

@article{fukunaga_branch_1975,
	title = {A Branch and Bound Algorithm for Computing k-Nearest Neighbors},
	volume = {C-24},
	issn = {0018-9340},
	doi = {10.1109/T-C.1975.224297},
	abstract = {Computation of the k-nearest neighbors generally requires a large number of expensive distance computations. The method of branch and bound is implemented in the present algorithm to facilitate rapid calculation of the k-nearest neighbors, by eliminating the necesssity of calculating many distances. Experimental results demonstrate the efficiency of the algorithm. Typically, an average of only 61 distance computations were made to find the nearest neighbor of a test sample among 1000 design samples.},
	number = {7},
	journal = {{IEEE} Transactions on Computers},
	author = {Fukunaga, K. and Narendra, Patrenahalli M.},
	month = jul,
	year = {1975},
	keywords = {Branch and bound, distance computation, hierarchical decomposition, k-nearest neighbors, tree-search algorithm.},
	pages = {750--753},
	file = {IEEE Xplore Abstract Record:E\:\\Papers\\Zotero Repository\\storage\\5PJI4JEX\\abs_all.html:text/html;IEEE Xplore Full Text PDF:E\:\\Papers\\Zotero Repository\\storage\\VKFHKX73\\Fukunaga 그리고 Narendra - 1975 - A Branch and Bound Algorithm for Computing k-Neare.pdf:application/pdf}
}

@inproceedings{brin_near_1995,
	address = {Zurich, Switzerland},
	title = {Near Neighbor Search in Large Metric Spaces},
	url = {http://ilpubs.stanford.edu:8090/113/},
	urldate = {2014-11-17},
	author = {Brin, S.},
	year = {1995},
	file = {Full Text PDF:E\:\\Papers\\Zotero Repository\\storage\\X876AVX7\\Brin - 1995 - Near Neighbor Search in Large Metric Spaces.pdf:application/pdf;Snapshot:E\:\\Papers\\Zotero Repository\\storage\\74CPSZSX\\113.html:text/html}
}

@inproceedings{moore_anchors_2000,
	address = {San Francisco, {CA}, {USA}},
	series = {{UAI}'00},
	title = {The Anchors Hierarchy: Using the Triangle Inequality to Survive High Dimensional Data},
	isbn = {1-55860-709-9},
	shorttitle = {The Anchors Hierarchy},
	url = {http://dl.acm.org/citation.cfm?id=2073946.2073993},
	abstract = {This paper is about metric data structures in high-dimensional or non-Euclidean space that permit cached sufficient statistics accelerations of learning algorithms. It has recently been shown that for less than about 10 dimensions, decorating kd-trees with additional "cached sufficient statistics" such as first and second moments and contingency tables can provide satisfying acceleration for a very wide range of statistical learning tasks such as kernel regression, locally weighted regression, k-means clustering, mixture modeling and Bayes Net learning. In this paper, we begin by defining the anchors hierarchy--a fast data structure and algorithm for localizing data based only on a triangle-inequality-obeying distance metric. We show how this, in its own right, gives a fast and effective clustering of data. But more importantly we show how it can produce a well-balanced structure similar to a Ball-Tree (Omohundro, 1991) or a kind of metric tree (Uhlmann, 1991; Ciaccia, Patella, \& Zezula, 1997) in a way that is neither "topdown" nor "bottom-up" but instead "middleout". We then show how this structure, decorated with cached sufficient statistics, allows a wide variety of statistical learning algorithms to be accelerated even in thousands of dimensions.},
	urldate = {2014-11-17},
	booktitle = {Proceedings of the Sixteenth Conference on Uncertainty in Artificial Intelligence},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Moore, Andrew W.},
	year = {2000},
	pages = {397--405},
	file = {ACM Full Text PDF:E\:\\Papers\\Zotero Repository\\storage\\BJW2A3CZ\\Moore - 2000 - The Anchors Hierarchy Using the Triangle Inequali.pdf:application/pdf}
}

@inproceedings{liu_investigation_2004,
	title = {An investigation of practical approximate nearest neighbor algorithms},
	abstract = {This paper concerns approximate nearest neighbor searching algorithms, which have become increasingly important, especially in high dimensional perception areas such as computer vision, with dozens of publications in recent years. Much of this enthusiasm is due to a successful new approximate nearest neighbor approach called Locality Sensitive Hashing ({LSH}). In this paper we ask the question: can earlier spatial data structure approaches to exact nearest neighbor, such as metric trees, be altered to provide approximate answers to proximity queries and if so, how? We introduce a new kind of metric tree that allows overlap: certain datapoints may appear in both the children of a parent. We also introduce new approximate k-{NN} search algorithms on this structure. We show why these structures should be able to exploit the same randomprojection-based approximations that {LSH} enjoys, but with a simpler algorithm and perhaps with greater efficiency. We then provide a detailed empirical evaluation on five large, high dimensional datasets which show up to 31-fold accelerations over {LSH}. This result holds true throughout the spectrum of approximation levels.},
	publisher = {{MIT} Press},
	author = {Liu, Ting and Moore, Andrew W. and Gray, Alexander and Yang, Ke},
	year = {2004},
	pages = {825--832},
	file = {Citeseer - Full Text PDF:E\:\\Papers\\Zotero Repository\\storage\\XCIMMAFZ\\Liu et al. - 2004 - An investigation of practical approximate nearest .pdf:application/pdf;Citeseer - Snapshot:E\:\\Papers\\Zotero Repository\\storage\\69AMS7WI\\summary.html:text/html}
}

@techreport{cannons_review_2008,
	address = {York University},
	type = {Technical Report},
	title = {A Review of Visual Tracking},
	abstract = {This report contains a review of visual tracking in monocular video sequences. For the purpose of this review, the majority of the visual trackers in the literature are divided into three tracking categories: discrete feature trackers, contour trackers, and region-based trackers. This categorization was performed based on the features used and the algorithms employed by the various visual trackers. The first class of trackers represents targets as discrete features (e.g. points, sets of points, lines) and performs data association using a distance metric that accommodates the particular feature. Contour trackers provide precise outlines of the target boundaries, meaning that they must not only uncover the position of the target, but its shape as well. Contour trackers often make use of gradient edge information during the tracking process. Region trackers represent the target with area-based descriptors that define its support and attempt to locate the image region in the current frame that best matches an object template. Trackers that are not in agreement with the abovementioned categorization, including those that combine methods from the three defined classes, are also considered in this review. In addition to categorizing and describing the various visual trackers in the literature, this review also provides a commentary on the current state of the field as well as a comparative analysis of the various approaches. The paper concludes with an outline of open problems in visual tracking.},
	number = {{CSE}-2008-07},
	author = {Cannons, Kevin},
	month = sep,
	year = {2008},
	file = {Cannons - 2008 - A Review of Visual Tracking.pdf:E\:\\Papers\\Zotero Repository\\storage\\9BJTN2DQ\\Cannons - 2008 - A Review of Visual Tracking.pdf:application/pdf}
}

@incollection{iglesias_evaluation_2014,
	series = {Lecture Notes in Computer Science},
	title = {Evaluation of Keypoint Descriptors for Gender Recognition},
	copyright = {©2014 Springer International Publishing Switzerland},
	isbn = {978-3-319-12567-1, 978-3-319-12568-8},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-12568-8_69},
	abstract = {Gender recognition is a relevant problem due to the number and importance of its possible application areas. The challenge is to achieve high recognition rates in the shortest possible time. Most studies are based on Local Binary Patterns ({LBP}) and its variants to estimate gender. In this paper, we propose the use of Binary Robust Independent Elementary Features ({BRIEF}), Oriented {FAST} and Rotated {BRIEF} ({ORB}) and Binary Robust Invariant Scalable Keypoints ({BRISK}) in gender recognition due to their good performance and speed. The aim is to show that {ORB} and {BRISK} are faster than {LBP} but allow to achieve similar recognition rates, which makes them suitable for real-time systems. For the best of our knowledge, it has not been studied in literature.},
	language = {en},
	number = {8827},
	urldate = {2014-11-10},
	booktitle = {Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications},
	publisher = {Springer International Publishing},
	author = {Iglesias, Florencia Soledad and Buemi, María Elena and Acevedo, Daniel and Jacobo-Berlles, Julio},
	editor = {Bayro-Corrochano, Eduardo and Hancock, Edwin},
	month = jan,
	year = {2014},
	keywords = {Algorithm Analysis and Problem Complexity, Artificial Intelligence (incl. Robotics), Biometrics, Gender recognition, Image Processing and Computer Vision, Information Systems Applications (incl. Internet), Keypoint Descriptors, {LBP}, Pattern Recognition},
	pages = {564--571},
	file = {Full Text PDF:E\:\\Papers\\Zotero Repository\\storage\\5UICNMQG\\Iglesias et al. - 2014 - Evaluation of Keypoint Descriptors for Gender Reco.pdf:application/pdf;Snapshot:E\:\\Papers\\Zotero Repository\\storage\\QJA79CHI\\978-3-319-12568-8_69.html:text/html}
}

@incollection{niedermayer_retrieval_2014,
	series = {Lecture Notes in Computer Science},
	title = {Retrieval of Binary Features in Image Databases: A Study},
	copyright = {©2014 Springer International Publishing Switzerland},
	isbn = {978-3-319-11987-8, 978-3-319-11988-5},
	shorttitle = {Retrieval of Binary Features in Image Databases},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-11988-5_14},
	abstract = {Many state-of-the art object recognition systems rely on local image features, sometimes hundreds per image, that describe the surroundings of detected interest points by a high-dimensional feature vector. To recognize objects, these systems have to match features detected in a query image against the features stored in a database containing millions or even billions of feature vectors. Hence, efficient matching is crucial for real applications. In the past, feature vectors were often real-valued, and therefore research focused on such feature representations. Present techniques, however, involve binary features to reduce memory consumption and to speed up the feature extraction stage. Matching such binary features received relatively little attention in the computer vision community. Often, either Locality Sensitive Hashing ({LSH}) or quantization-based techniques, that are known from real-valued features, are used. However, an in-depth evaluation of the involved parameters in binary space has, to the best of our knowledge, not yet been performed. In this paper, we aim at closing this research gap, providing valuable insights for application-oriented research.},
	language = {en},
	number = {8821},
	urldate = {2014-11-10},
	booktitle = {Similarity Search and Applications},
	publisher = {Springer International Publishing},
	author = {Niedermayer, Johannes and Kröger, Peer},
	editor = {Traina, Agma Juci Machado and Jr, Caetano Traina and Cordeiro, Robson Leonardo Ferreira},
	month = jan,
	year = {2014},
	keywords = {Algorithm Analysis and Problem Complexity, Database Management, Data structures, Information Storage and Retrieval, Numeric Computing, Pattern Recognition},
	pages = {151--163},
	file = {Full Text PDF:E\:\\Papers\\Zotero Repository\\storage\\IM2EKKVM\\Niedermayer 그리고 Kröger - 2014 - Retrieval of Binary Features in Image Databases A.pdf:application/pdf;Snapshot:E\:\\Papers\\Zotero Repository\\storage\\DDICGI45\\978-3-319-11988-5_14.html:text/html}
}

@incollection{ma_fast_2014,
	series = {Lecture Notes in Computer Science},
	title = {Fast Search of Binary Codes with Distinctive Bits},
	copyright = {©2014 Springer International Publishing Switzerland},
	isbn = {978-3-319-13167-2, 978-3-319-13168-9},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-13168-9_31},
	abstract = {Although distance between binary codes can be computed fast in hamming space, linear search is not practical for large scale dataset. Therefore attention has been paid to the efficiency of performing approximate nearest neighbor search, in which Hierarchical Clustering Trees ({HCT}) is the state-of-the-art method. However, {HCT} builds index with the whole binary codes, which degrades search performance. In this paper, we first propose an algorithm to compress binary codes by extracting distinctive bits according to the standard deviation of each bit. Then, a new index is proposed using com-pressed binary codes based on hierarchical decomposition of binary spaces. Experiments conducted on reference datasets and a dataset of one billion binary codes demonstrate the effectiveness and efficiency of our method.},
	language = {en},
	number = {8879},
	urldate = {2014-11-10},
	booktitle = {Advances in Multimedia Information Processing – {PCM} 2014},
	publisher = {Springer International Publishing},
	author = {Ma, Yanping and Xie, Hongtao and Chen, Zhineng and Dai, Qiong and Huang, Yinfei and Ji, Guangrong},
	editor = {Ooi, Wei Tsang and Snoek, Cees G. M. and Tan, Hung Khoon and Ho, Chin-Kuan and Huet, Benoit and Ngo, Chong-Wah},
	month = jan,
	year = {2014},
	keywords = {approximate nearest neighbor search, binary codes, binary indexing, Data Mining and Knowledge Discovery, Image Processing and Computer Vision, Information Systems Applications (incl. Internet), Multimedia Information Systems, Pattern Recognition, User Interfaces and Human Computer Interaction},
	pages = {274--283},
	file = {Full Text PDF:E\:\\Papers\\Zotero Repository\\storage\\HIUZWEBG\\Ma et al. - 2014 - Fast Search of Binary Codes with Distinctive Bits.pdf:application/pdf;Snapshot:E\:\\Papers\\Zotero Repository\\storage\\KGN3B4JU\\978-3-319-13168-9_31.html:text/html}
}